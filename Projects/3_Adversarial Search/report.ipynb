{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My `CustomPlayer` uses the same minimax algorithm implemented in `search_players.py`. However, it uses iterative deepening (ID) from depth 3 since in the late game, there are only few liberties, so minimax can search deeper within the time limit. It also uses alpha-beta pruning ($\\alpha\\beta$) and Principal Variation search (PV) to search less nodes.\n",
    "\n",
    ".\n",
    "\n",
    "For the first move, where I choose the starting position, I choose a position with 8 liberties (8L) instead of the basic random choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance against Sample Players"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                   | Random | Greedy | Minimax (3) |\n",
    "|-----------------------------------|--------|--------|-------------|\n",
    "| Minimax (3)                       |  94.0% |  70.8% |       49.5% |\n",
    "| Minimax (3) + 8L                  |  93.5% |  48.8% |       55.2% |\n",
    "| Minimax (3) + 2L                  |  91.5% |  62.2% |       51.5% |\n",
    "| Minimax + ID                      |  95.8% |  84.5% |       74.0% |\n",
    "| Minimax + ID + $\\alpha\\beta$      |  97.2% |  87.2% |       73.5% |\n",
    "| Minimax + ID + $\\alpha\\beta$ + CH |  95.2% |  89.8% |       76.2% |\n",
    "| Minimax + ID + $\\alpha\\beta$ + PV |        |        |             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Each number in this chart is a result of 100 rounds (400 games) on 4 processes with fair matches flag enabled.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choose a baseline search algorithm for comparison (for example, alpha-beta search with iterative deepening, etc.). How much performance difference does your agent show compared to the baseline?\n",
    "Why do you think the technique you chose was more (or less) effective than the baseline?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the baseline search algorithm I use alpha-beta search with iterative deepening. Adding Principal Variation search..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe in this game, the second player can always win by mirroring each action taken by the first player. Since the board is 8x8, there is no place that can break the symmetry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ideas I have in improving the model that failed. Here is a chart with a full list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                   | Random | Greedy | Minimax (3) |\n",
    "|-----------------------------------|--------|--------|-------------|\n",
    "| Minimax (3)                       |  94.0% |  70.8% |       49.5% |\n",
    "| Minimax (3) + 8L                  |  93.5% |  48.8% |       55.2% |\n",
    "| Minimax (3) + 2L                  |  91.5% |  62.2% |       51.5% |\n",
    "| Minimax + ID                      |  95.8% |  84.5% |       74.0% |\n",
    "| Minimax + ID + $\\alpha\\beta$      |  97.2% |  87.2% |       73.5% |\n",
    "| Minimax + ID + $\\alpha\\beta$ + CH |  95.2% |  89.8% |       76.2% |\n",
    "| Minimax + ID + $\\alpha\\beta$ + PV |        |        |             |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
